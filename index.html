<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Red Teaming Vision-Language-Action Models via Quality Diversity Prompt Generation for Robust Robot Policies.">
  <meta name="keywords" content="Q-DIG, VLA, Red-Teaming">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Red Teaming Vision-Language-Action Models via Quality Diversity Prompt Generation for Robust Robot Policies</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>

</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Red Teaming Vision-Language-Action Models via Quality Diversity Prompt Generation for Robust Robot Policies</h1>
          <div class="is-size-5 publication-authors">
            Anonymous Authors
            <!-- <span class="author-block">
              <a href="https://keunhong.com">Keunhong Park</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://utkarshsinha.com">Utkarsh Sinha</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://jonbarron.info">Jonathan T. Barron</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="http://sofienbouaziz.com">Sofien Bouaziz</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.danbgoldman.com">Dan B Goldman</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
            </span> -->
          </div>

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Washington,</span>
            <span class="author-block"><sup>2</sup>Google Research</span>
          </div> -->

          <!-- <div class="column has-text-centered">
            <div class="publication-links">

              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div> -->



        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" controls loop playsinline height="100%" poster="./static/images/main_fig_v4.jpg">
        <source src="./static/videos/Q_Dig_Vid.mov"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Q-DIG</span> (<b>Q</b>uality Diversity for <b>D</b>iverse <b>I</b>nstruction <b>G</b>eneration) generates challenging<br>and human-like instructions for Vision-Language-Action models.
      </h2>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <video poster="" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/Q_Dig_Vid.mov" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/Q_Dig_Vid.mov" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/Q_Dig_Vid.mov" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/Q_Dig_Vid.mov" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/Q_Dig_Vid.mov" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/Q_Dig_Vid.mov" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/Q_Dig_Vid.mov" type="video/mp4">
          </video>
        </div>
        <div class="item">
          <video poster="" autoplay muted loop playsinline height="100%">
            <source src="./static/videos/Q_Dig_Vid.mov" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Vision-Language-Action (VLA) models have sig-
nificant potential to enable general-purpose robotic systems for
a range of vision-language tasks. However, the performance of
VLA-based robots is highly sensitive to the precise wording of
language instructions, and it remains difficult to predict when
such robots will fail. To improve the robustness of VLAs to
different wordings, we present Q-DIG (Quality Diversity for
Diverse Instruction Generation), which performs red-teaming
by scalably identifying diverse natural language task descrip-
tions that induce failures while remaining task-relevant. Q-
DIG integrates Quality Diversity (QD) techniques with Vision-
Language Models (VLMs) to generate a broad spectrum of
adversarial instructions that expose meaningful vulnerabilities
in VLA behavior. Our results across multiple simulation bench-
marks show that Q-DIG finds more diverse and meaningful
failure modes compared to baseline methods, and that fine-
tuning VLAs on the generated instructions improves task
success rates. Furthermore, results from a user study highlight
that Q-DIG generates prompts judged to be more natural and
human-like than those from baselines. Together, these findings
suggest that Q-DIG is a promising approach for identifying
vulnerabilities and improving the robustness of VLA-based
robots.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Method Overview. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Method Overview</h2>
        <div class="hero-body">
          <img src="./static/images/pipeline_v06.jpg" alt="Q-DIG Method Pipeline" width="100%"/>
        </div>
        <div class="content has-text-justified">
          <p>
            Q-DIG leverages previously generated instructions as in-context examples to generate new adversarial instructions in target attack styles. Our method consists of three main steps:
          </p>
          <p>
            <strong>(1) Instruction Generation:</strong> Starting from an original task instruction, Q-DIG uses a Vision-Language Model (VLM) as a mutator to generate candidate instructions in target attack styles (e.g., "use of adverbs", "casual style"). The VLM leverages in-context learning with previously discovered instructions and visual context from the task.
          </p>
          <p>
            <strong>(2) Instruction Evaluation:</strong> Generated instructions are evaluated by simulating the base VLA on the task to compute failure variance and an LLM judge categorizes each instruction into semantic attack styles. This provides both quality and diversity measures for the Quality Diversity optimization.
          </p>
          <p>
            <strong>(3) Archive Update:</strong> Instructions inducing high failure rates with different attack styles are stored in an archive. Each archive cell corresponds to a specific attack style category, and only the best-performing instruction for each style is retained, providing high-quality and diverse examples for future iterations.
          </p>
        </div>
      </div>
    </div>
    <!--/ Method Overview. -->

    <!-- Diversity Analysis. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Instruction Diversity & Quality</h2>
        <div class="content has-text-justified">
          <p>
            Q-DIG generates more diverse adversarial instructions compared to baseline methods while maintaining high failure variance. Our method achieves superior performance across multiple diversity metrics including BERT diversity, BLEU diversity, and archive coverage across different attack styles.
          </p>
        </div>
        <div class="columns">
          <div class="column is-4">
            <img src="./static/images/Diversity_page-0001.jpg" alt="Diversity Comparison Results" width="100%"/>
          </div>
          <div class="column is-4">
            <img src="./static/images/Failure_Variance_page-0001.jpg" alt="Failure Variance Results" width="100%"/>
          </div>
          <div class="column is-4">
            <img src="./static/images/Diversity_to_OG_page-0001.jpg" alt="Diversity to Original Comparison" width="100%"/>
          </div>
        </div>
        <div style="margin: 30px 0;">
          <table class="table is-bordered" style="width: 80%; margin: auto;">
            <thead>
              <tr>
                <th>Metric (Domain)</th>
                <th>Rephrase</th>
                <th>ERT</th>
                <th>Q-DIG</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>BLEU (LIBERO)</strong></td>
                <td><strong>0.963</strong><sub>0.003</sub></td>
                <td>0.951<sub>0.01</sub></td>
                <td>0.947<sub>0.01</sub></td>
              </tr>
              <tr>
                <td><strong>BLEU (SimplerEnv)</strong></td>
                <td>0.928<sub>0.01</sub></td>
                <td>0.936<sub>0.01</sub></td>
                <td><strong>0.946</strong><sub>0.01</sub></td>
              </tr>
              <tr>
                <td><strong>Coverage (LIBERO)</strong></td>
                <td>0.363<sub>0.02</sub></td>
                <td>0.325<sub>0.01</sub></td>
                <td><strong>0.972</strong><sub>0.02</sub></td>
              </tr>
              <tr>
                <td><strong>Coverage (SimplerEnv)</strong></td>
                <td>0.388<sub>0.03</sub></td>
                <td>0.325<sub>0.02</sub></td>
                <td><strong>0.913</strong><sub>0.02</sub></td>
              </tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>
    <!--/ Diversity Analysis. -->


    <!-- Performance Comparison. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Baseline Comparisons</h2>
        <div class="content has-text-justified">
          <p>
            Compare results between OpenVLA and Fine-tuned OpenVLA across various original and adversarial prompts to demonstrate improved robustness.
          </p>
        </div>
        <div class="box mt-0 mb-0">
          <div class="columns is-centered">
            <div class="column is-narrow">
              <div class="field">
                <label class="label">Choose a task to view baseline comparisons:</label>
                <div class="control">
                  <div class="select">
                    <select id="baseline-selector">
                      <option value="lift_ball">(Original prompt) Pick up the Coke can</option>
                      <option value="lift_tray">(Adversarial prompt) Carefully grab that soda can, buddy!</option>
                      <option value="push_box">(Original prompt) Open the top drawer</option>
                      <option value="push_buttons">(Adversarial prompt) Gently slide open the upper compartment</option>
                      <option value="straighten_rope">(Original prompt) Close the bottom drawer</option>
                    </select>
                  </div>
                </div>
              </div>
            </div>
          </div>

          <div class="columns is-centered mt-4">
            <div class="column">
              <div id="baseline-container" class="has-text-centered">
                <!-- Lift Ball -->
                <div id="lift_ball" class="baseline-comparison">
                  <div class="columns">
                    <div class="column is-6">
                      <h5 class="title is-5">OpenVLA</h5>
                      <video controls="" muted="" style="width: 90%; height: 85%; min-height: 218px;">
                        <source src="./static/videos/baseline/CLB/OpenVLA_CLB.mp4" type="video/mp4">
                      </video>
                    </div>

                    <div class="column is-6">
                      <h5 class="title is-5">Fine-tuned OpenVLA</h5>
                      <video controls="" muted="" style="width: 90%; height: 85%; min-height: 218px;">
                        <source src="./static/videos/baseline/CLB/FinetunedOpenVLA_CLB.mp4" type="video/mp4">
                      </video>
                    </div>
                  </div>
                </div>

                <!-- Lift Tray -->
                <div id="lift_tray" class="baseline-comparison" style="display: none;">
                  <div class="columns">
                    <div class="column is-6">
                      <h5 class="title is-5">OpenVLA</h5>
                      <video controls="" muted="" style="width: 90%; height: 85%; min-height: 218px;">
                        <source src="./static/videos/baseline/CLT/OpenVLA_CLT.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="column is-6">
                      <h5 class="title is-5">Fine-tuned OpenVLA</h5>
                      <video controls="" muted="" style="width: 90%; height: 85%; min-height: 218px;">
                        <source src="./static/videos/baseline/CLT/FinetunedOpenVLA_CLT.mp4" type="video/mp4">
                      </video>
                    </div>
                  </div>
                </div>

                <!-- Push Box -->
                <div id="push_box" class="baseline-comparison" style="display: none;">
                  <div class="columns">
                    <div class="column is-6">
                      <h5 class="title is-5">OpenVLA</h5>
                      <video controls="" muted="" style="width: 90%; height: 85%; min-height: 218px;">
                        <source src="./static/videos/baseline/CPB/OpenVLA_CPB.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="column is-6">
                      <h5 class="title is-5">Fine-tuned OpenVLA</h5>
                      <video controls="" muted="" style="width: 90%; height: 85%; min-height: 218px;">
                        <source src="./static/videos/baseline/CPB/FinetunedOpenVLA_CPB.mp4" type="video/mp4">
                      </video>
                    </div>
                  </div>
                </div>

                <!-- Coordinated Put Item In Drawer -->
                <div id="push_buttons" class="baseline-comparison" style="display: none;">
                  <div class="columns">
                    <div class="column is-6">
                      <h5 class="title is-5">OpenVLA</h5>
                      <video controls="" muted="" style="width: 90%; height: 85%; min-height: 218px;">
                        <source src="./static/videos/baseline/CPID/OpenVLA_CPID.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="column is-6">
                      <h5 class="title is-5">Fine-tuned OpenVLA</h5>
                      <video controls="" muted="" style="width: 90%; height: 85%; min-height: 218px;">
                        <source src="./static/videos/baseline/CPID/FinetunedOpenVLA_CPID.mp4" type="video/mp4">
                      </video>
                    </div>
                  </div>
                </div>

                <!-- Straighten Rope -->
                <div id="straighten_rope" class="baseline-comparison" style="display: none;">
                  <div class="columns">
                    <div class="column is-6">
                      <h5 class="title is-5">OpenVLA</h5>
                      <video controls="" muted="" style="width: 90%; height: 85%; min-height: 218px;">
                        <source src="./static/videos/baseline/BSR/OpenVLA_BSR.mp4" type="video/mp4">
                      </video>
                    </div>
                    <div class="column is-6">
                      <h5 class="title is-5">Fine-tuned OpenVLA</h5>
                      <video controls="" muted="" style="width: 90%; height: 85%; min-height: 218px;">
                        <source src="./static/videos/baseline/BSR/FinetunedOpenVLA_BSR.mp4" type="video/mp4">
                      </video>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <!--/ Performance Comparison. -->

    <!-- Experimental Results. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Experimental Results</h2>
        <div class="content has-text-justified">
          <p>
            Comprehensive evaluation results across SimplerEnv and LIBERO benchmarks. Our experiments demonstrate that Q-DIG generates more human-like instructions compared to baselines and that fine-tuning with these instructions leads to substantial improvements in VLA robustness.
          </p>
        </div>
        <div style="margin: 30px 0;">
          <table class="table is-bordered" style="width: 90%; margin: auto;">
            <thead>
              <tr>
                <th>Finetuned Model / Prompts</th>
                <th>Original</th>
                <th>Rephrase</th>
                <th>ERT</th>
                <th>Q-DIG</th>
                <th>Avg.</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><strong>Original</strong></td>
                <td><strong>97.4%</strong></td>
                <td>90.3%</td>
                <td>66.2%</td>
                <td>63.9%</td>
                <td>75.5%</td>
              </tr>
              <tr>
                <td><strong>Rephrase</strong></td>
                <td>62.2%</td>
                <td>63.4%</td>
                <td>53.3%</td>
                <td>47.6%</td>
                <td>55.8%</td>
              </tr>
              <tr>
                <td><strong>ERT</strong></td>
                <td>94.6%</td>
                <td><strong>90.8%</strong></td>
                <td><strong>91.1%</strong></td>
                <td>76.4%</td>
                <td><strong>87.3%</strong></td>
              </tr>
              <tr>
                <td><strong>Q-DIG</strong></td>
                <td>93.8%</td>
                <td>84.7%</td>
                <td>66.9%</td>
                <td><strong>88.9%</strong></td>
                <td>82.1%</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div class="hero-body">
          <img src="./static/images/experimental_results.png" alt="Experimental Results" width="100%" style="margin-bottom: 20px;"/>
        </div>
      </div>
    </div>
    <!--/ Experimental Results. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>

<!-- 
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. See <a
            href="https://github.com/nerfies/nerfies.github.io">here</a> for the source code.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
